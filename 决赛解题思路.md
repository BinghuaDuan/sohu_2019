# <center><font size=5>搜狐内容识别算法大赛解决方案</font></center>

> **队伍名：我想去北京**

##  <font size=4>1. 解题思路</font>

&emsp;本次比赛任务是根据实际的新闻文本，提取其中的关键实体以及判断新闻对关键实体的情感。我们将题目分成两个任务来完成，即**关键实体抽取和Aspect情感分析**。

&emsp;首先描述实体抽取任务的解答思路。关键实体抽取即从新闻文本中提取实体词并判断是否是新闻描述的核心实体，所以将该问题分解为两个部分 —— **实体词提取和是否是关键实体的判断**。

## <font size=4>2. 实体部分</font>

###  <font size=3>2.1 数据预处理</font>

1. 实体词抽取我们首先采用`jieba`库对文本进行分词，如果直接进行分词，那么分词结果对训练集实体的覆盖率只能达到`35%~36%`左右，这显然无法得到比较好的结果。由于分词的结果对之后预测起着比较重要的作用，所以我们需要根据新闻文本的特性搜索一些实体词库，加载为分词的参照词典。通过对训练集和测试集文本的分析，发现这些文本主要包含了最近几个月来的热门话题，主要包括**科技类、娱乐类、时事热点、问答类**等。基于这样的文本特性，我们有目的性的获取了最近在科技、娱乐、时事等方面比较热门的关键实体，作为实体字典加载到`jieba`分词库中。加入词典之后，分词结果对训练集实体的覆盖率可以达到`84%`左右。



2. 在分词之前，首先对文本进行一些清洗。基于对文本的分析，发现文本中存在着一些**html标记以及大量的url网址**，这些对分词以及判断会造成干扰，所以通过正则表达式去除。接着，对文本进行分词，得到分词结果。



3. 为之后提取特征做准备，我们需要基于分词结果训练一些用于生成特征的模型，包括`tfidf, word2vec, doc2vec, lda, kmeans`等。除了传统的`tfidf`以及词向量、文本向量之外，我们创新性的加入了LDA主题模型以及KMeans聚类作为分类的特征。LDA主题模型主要基于不同文档中单词的共现性，通过很好地获取相似词比较多的相关文本的类别信息；KMeans我们使用文档向量在高维空间进行聚类，能够比较好的获取语义上相关的文本的类别信息。要说明的是，通过对搜狐新闻网站的话题分布观察，我们选择10作为LDA主题数以及KMeans聚类的类别数。

###  <font size=3>2.2  候选词集的获取</font>

1. **基于jieba分词的方法**：最简单的获取候选词集的方法就是通过使用中文分词工具`jieba`，除此之外，还尝试使用`pkuseg`、`hanlp`进行分词。我们发现在使用`jieba`分词工具在 load 词典的方式下，可以实现对测试集的覆盖率达到`84.7%`。

2. **基于n-gram分词的方法**： 基于n-gram的思想，我们采用`bigram`和`trigram`的方法，将相邻的2个和3个词进行组合，并通过设置在文本中出现的次数为阈值，进行筛选。在`jieba`分词的基础上，使用这种方法最高可以达到`89.5%`。

3. **基于Bert的序列标注方法**：通过使用bert模型，对文本进行序列标注，有利于获取长词，纯Bert得到的词对训练集的覆盖率可以达到`71.4%`；通过和上面的方法结合，最终可以实现对训练集实体的覆盖率达到`94.5%`。

   BERT的流程图见PPT。


###  <font size=3>2.3  特征工程</font>

1. 基于上面得到的分词结果以及训练的模型，我们进行了特征工程，共计得到了34个特征。包括：
   - **`cixing`**: 单词的词性。
   - **`tf`**: 词频，即单词在该条新闻中出现的次数。
   - **`tf_ratio`**: 词频比例，单词出现次数在所有词次数的占比。
   - **`word_len`**: 单词的长度。
   - **`word_distrance_norm`**: 归一化之后的词跨度，所谓词跨度是指：单词首次出现的最后一个字符的位置到单词最后一次出现第一个字符位置之间的单词数，并基于单个文本的词跨度进行归一化。
   - **`tfidf`**: 根据之前训练的tfidf模型获取单词的`tfidf`值，对OOV的词用0填充，并基于单个文本对`tfidf`值进行归一化。
   - **`text_rank`**: 基于`jieba`库中的`text_rank`算法得到单词的得分，对OOV单词用`nan`填充
   - **`Cosine`**: 计算词向量和文本向量之间的余弦距离，一定程度上反映了单词和文本语义上的相似性。
   - **`Euclidean`**: 计算词向量和文本向量之间的欧氏距离。
   - **`pearson_cor`**: 计算词向量和文本向量之间的皮尔逊相关系数。
   - **`pearson_pvalue`**: 计算词向量和文本向量之间的p值相关度。
   - **`ocur_in_title`**: 单词是否在标题中出现。
   - **`has_num`**: 单词是否有数字。
   - **`has_char`**: 单词是否有字母。
   - **`coocur_skew`**: 单词共现矩阵的偏度。
   - **`coocur_var`**: 单词共现矩阵的方差。
   - **`coocur_mean`**: 单词共现矩阵的均值。
   - **`coocur_kurt`**: 单词共现矩阵的峰度。
   - **`mean_sim_tags`**: 词向量和词向量相似度的均值。
   - **`skew_sim_tags`**: 词向量和词向量相似度的偏度。
   - **`kurt_sim_tags`**: 词向量和词向量相似度的峰度。
   - **`diff_mean_sim_tags`**: 相似度矩阵差分之后的均值。
   - **`diff_skew_sim_tags`**: 相似度矩阵差分之后的偏度。
   - **`diff_kurt_sim_tags`**: 相似度矩阵差分之后的峰度。
   - **`be_include_sum`**: 被包含关系的和。
   - **`be_include_mean`**: 被包含关系的均值。
   - **`be_include_var`**: 被包含关系的方差。
   - **`be_include_std`**: 被包含关系的标准差。
   - **`be_include_skew`**: 被包含关系的偏度。
   - **`be_include_kurt`**: 被包含关系的峰度。
   - **`include_sum`**: 包含关系的和。
   - **`include_mean`**: 包含关系的均值。
   - **`include_var`**: 包含关系的方差。
   - **`include_std`**: 包含关系的标准差。
   - **`include_skew`**: 包含关系的峰度。
   - **`include_kurt`**: 包含关系的偏度。
   - **`tfidf_index`**: tfidf排名并进行归一化，和tfidf配合，区别不同文档的tfidf值。
   - **`tf_index`**: 对词频进行排名。
   - **`word_distance_norm_index`**: 对词跨度进行排名。
   - **`cosine_index`**: 对`Cosine`特征进行排名。
   - **`euclidean_index`**: 对`Euclidean`进行排名。
   - **`idf`**: 逆词频信息，单词在训练集和测试集中多少个不同文档中出现。
   - **`kmeans_classes`**: 文档KMeans聚类特征。
   - **`lda_classes`**: 文档LDA主题特征。
   - **`num_in_gt`**: 单词在训练集实体中出现的次数，为了防止过多的leaky，选择至少出现在20篇不同文档中的单词。
   - **`ctr`**: 单词作为实体的转化率，即出现在实体中的次数/出现的不同文档数，为了防止过多leaky，选择至少出现在20篇不同文档中的单词，并且使用贝叶斯平滑。



2. 基于上面的特征，我们并没有选择全部的分词得到的单词加入训练集和测试集，而是选择了长度大于1的单词，进行了初步的筛选。之后，我们进行了一些后处理，删除了一些对最后结果影响较多的干扰词和纯数字的单词。

###  <font size=3>2.4  模型训练</font>

&emsp;基于上面得到的特征，使用树模型进行训练。我们采用了3种常用的树模型库分别进行训练，并进行了特征选择和调参。

1. 在lightgbm模型中，经过一定的特征选择和调参，得到的单模型实体F1值线上最好成绩为`0.5960`。

2. 单独模型跑出来的结果是每个单词是实体的概率，而题目要求选出来的实体不超过3个，所以涉及每篇文章实体个数选择的问题。我们设计了一个5次阈值搜索的方法，根据预测得到的绝对概率和基于单文本的相对概率，在验证集搜索最佳的划分阈值，基于得到的分割阈值，对测试集的结果进行判断，选出每篇文章中的实体。


###  <font size=3>2.5  其他尝试</font>

- 为了预测每篇文档实体的个数，我们尝试构建一个实体数量预测的模型，使用树模型和神经网络模型分别进行了实体，验证集的准确率最高只有40%，所以选择放弃了这个模型。

- 对于单词属于实体概率的预测，我们还尝试了随机森林、MLP的方法，并且通过对多模型averaing和stacking，但是都没有得到更好的效果。所以最终选择根据不同模型预测结果进行融合。


### <font size=3>2.6 模型融合以及后处理</font>

&emsp;我们队伍三个人都是用lgb模型做的,但是由于分词的覆盖率不行,得到的结果必然少了些实体。我们观察到我们的bert的结果文件非常大,但是实体分数只有30多分,说明实体的召回率不差。
这也体现了bert能发现新词,和拟合原来的词语,所以bert弥补了我们分词的不足。我们跑出来了3个bert的结果,6个树模型的结果，bert结果取并集,树模型的结果我们用投票机制,只要实体出现的次数大于3，那我我们就保留这个实体。我们用bert来筛选我们用树模型保留下来的实体,如果实体出现在bert中,那么留下它,否则去除,  但是光用bert筛选是不够的,我们对文章进行观察,发现了以下几个规则:

- 每篇文章的标题基本上都有一个实体,所以可以加上标题进行补充。例如,经过bert筛选后,可能词语都被去除了,那么我们留下bert和树模型中在标题中出现的实体。

- 在标题中有书名号的词基本上都是实体,我们直接用正则表达式取出。


- 英文在标题中基本上也都是关键实体,我们直接用正则表达式取出。


- 使用贝叶斯平滑后的出现次数大于20的实体,如果其转化率排序前750个词语构建词表,再加上一些手机词表,对文章标题进行最大匹配,取出关键实体。


- 对bert筛选后的词语如果是英文,进行合并(实体+" "+实体)组成新实体,如果新实体在文章中,那么保留它,去掉原来两个短的英文实体。


- 如果中文实体存在包含关系,我们统计了比较长的实体的转化率,去除那些转化率小于0.15的长实体。


## <font size=4>3. 情感部分</font>

- 取出一篇文章中每个实体所在的句子,合并在一起,这样每个实体对应一个句子,我们对这个句子进行情感分析。

- 训练w2v词向量用于词嵌入。

- 句子长度为400,采用2层的双向lstm加上胶囊网络进行特征抽取,2层mlp,最后接一个softmax,优化函数用的adam,3个epoch。总共训练了10个模型,进行bagging。

- 最后与不同的词向量训练出来的结果进行融合,得出最终结果。

  模型结构见PPT。

